instance_type = "m7i.xlarge"      # Power User: 4 vCPUs, 16â€¯GB RAM, Intel Xeon (i7-class) â€” approx. $0.336/hr â†’ â‚±12,240/mo

/*
Change Quotas:
    Instance pricing:
        https://aws.amazon.com/ec2/pricing/on-demand/
        https://instances.vantage.sh/
    https://us-east-2.console.aws.amazon.com/servicequotas/home/services/ec2/quotas

    Set quota to 200

Instances for Video ğŸ¬: Hollywood-Grade Video Production & VFX Rendering:

    g4dn.medium     # Entry-Level Streaming & Transcoding: Great for testing, low-cost live stream pipelines, or preview rendering
    g4dn.xlarge     # Real-Time Video Encoding: Good for 1080p/4K encoding, cloud-based video editing, and game streaming setups
    g5.12xlarge     # VFX & Batch Rendering Node: Multi-GPU setup for rendering animations, visual effects, and 4K/8K editing
    g5.48xlarge     # Studio-Grade Render Farm Head: High-end render jobs, Unreal Engine builds, multi-stream 8K processing

Instances for AI ğŸ¤–: High-Performance Computing for Parallel Machine Learning Training:

    g4dn.xlarge     # Balanced Dev & Inference: Cost-effective entry point for ML model training, fine-tuning, and inference
    g5.12xlarge     # Mid-Scale AI Training: Multi-GPU A10G setup for larger models or batch inference
    p4d.24xlarge    # Large-Scale AI Training: 8Ã—A100 GPUs, suitable for deep learning and large-scale parallel training
    p5.48xlarge     # Extreme AI Training: 8Ã—H100 GPUs, optimal for LLMs, massive datasets, and top-tier AI workloads

GPU-Enabled Instances:

    instance_type = "g4dn.medium"     # Entry GPU Node: 2 vCPUs, 8â€¯GB RAM, 1Ã—NVIDIA T4 GPU (16â€¯GB) â€” â‚±14/hr â†’ â‚±10,300/mo
    instance_type = "g4dn.xlarge"     # â­ Lenovo Legion Equivalent â­ - GPU-Powered Power User: 4 vCPUs, 16â€¯GB RAM, 1Ã—NVIDIA T4 GPU (16â€¯GB) â€” â‚±30/hr â†’ â‚±21,800/mo
    instance_type = "g5.12xlarge"     # VFX Rendering: 48 vCPUs, 192â€¯GB RAM, 4Ã—NVIDIA A10G GPUs (24â€¯GB each) â€” â‚±323/hr â†’ â‚±235,800/mo
    instance_type = "g5.48xlarge"     # Studio Node: 192 vCPUs, 768â€¯GB RAM, 8Ã—NVIDIA A10G GPUs (24â€¯GB each) â€” â‚±1,293/hr â†’ â‚±942,000/mo
    instance_type = "p4d.24xlarge"    # Neural Renderer: 96 vCPUs, 1.1â€¯TB RAM, 8Ã—NVIDIA A100 GPUs (40â€¯GB each) â€” â‚±1,868/hr â†’ â‚±1.36â€¯M/mo
    instance_type = "p5.48xlarge"     # Hollywood-Grade: 192 vCPUs, 1.9â€¯TB RAM, 8Ã—NVIDIA A100 GPUs (80â€¯GB each) â€” â‚±3,705/hr â†’ â‚±2.70â€¯M/mo

Non-GPU Instances:

    instance_type = "t3.small"        # Budget: 2 vCPUs, 2â€¯GB RAM, Intel/AMD x86 â€” â‚±1.19/hr â†’ â‚±867/mo
    instance_type = "t3.medium"       # Best Balance: 2 vCPUs, 4â€¯GB RAM, x86 â€” â‚±2.37/hr â†’ â‚±1,730/mo
    instance_type = "c5ad.large"      # Budget Compute Node: 2 vCPUs, 4â€¯GB RAM â€” â‚±4.90/hr â†’ â‚±3,577/mo
    instance_type = "m7i.xlarge"      # Power User: 4 vCPUs, 16â€¯GB RAM, Intel Xeon (i7-class) â€” â‚±11.49/hr â†’ â‚±8,390/mo
    instance_type = "m7i.2xlarge"     # Advanced User: 8 vCPUs, 32â€¯GB RAM â€” â‚±38.30/hr â†’ â‚±27,960/mo
    instance_type = "c7i.2xlarge"     # High Performance: 8 vCPUs, 16â€¯GB RAM â€” â‚±40.11/hr â†’ â‚±29,280/mo
    instance_type = "r7i.xlarge"      # Memory Optimized: 4 vCPUs, 32â€¯GB RAM â€” â‚±28.73/hr â†’ â‚±20,970/mo
    instance_type = "m7i.4xlarge"     # Power Developer: 16 vCPUs, 64â€¯GB RAM â€” â‚±76.06/hr â†’ â‚±55,530/mo
    instance_type = "c7i.4xlarge"     # Compute Heavy: 16 vCPUs, 32â€¯GB RAM â€” â‚±80.83/hr â†’ â‚±58,010/mo
    instance_type = "r7i.4xlarge"     # Data Cruncher: 16 vCPUs, 128â€¯GB RAM â€” â‚±57.46/hr â†’ â‚±41,940/mo
    instance_type = "m7i.8xlarge"     # Elite Workstation: 32 vCPUs, 128â€¯GB RAM â€” â‚±152.13/hr â†’ â‚±110,980/mo

Instances for RDS ğŸ›¢: Amazon Relational Database Service (Production-Ready Only)

General Purpose (Balanced CPU/Memory):
    instance_type = "db.t3.small"     # Entry-Level Production DB: 2 vCPUs, 2â€¯GB RAM â€” â‚±2.37/hr â†’ â‚±1,730/mo
    instance_type = "db.t3.medium"    # Small Production DB: 2 vCPUs, 4â€¯GB RAM â€” â‚±4.75/hr â†’ â‚±3,470/mo
    instance_type = "db.m5.large"     # Balanced Production DB: 2 vCPUs, 8â€¯GB RAM â€” â‚±13.49/hr â†’ â‚±9,850/mo
    instance_type = "db.m5.xlarge"    # Mid-Sized Production DB: 4 vCPUs, 16â€¯GB RAM â€” â‚±26.98/hr â†’ â‚±19,700/mo
    instance_type = "db.m6g.large"    # Graviton2 Balanced DB: 2 vCPUs, 8â€¯GB RAM (ARM) â€” â‚±12.07/hr â†’ â‚±8,800/mo

Memory Optimized (High RAM Workloads):
    instance_type = "db.r5.large"     # Memory-Optimized DB: 2 vCPUs, 16â€¯GB RAM â€” â‚±18.24/hr â†’ â‚±13,320/mo
    instance_type = "db.r5.xlarge"    # Memory-Optimized DB: 4 vCPUs, 32â€¯GB RAM â€” â‚±36.48/hr â†’ â‚±26,640/mo
    instance_type = "db.r6g.large"    # Graviton2 Memory-Optimized DB: 2 vCPUs, 16â€¯GB RAM (ARM) â€” â‚±16.41/hr â†’ â‚±11,980/mo
    instance_type = "db.r6i.large"    # Intel Memory-Optimized DB: 2 vCPUs, 16â€¯GB RAM â€” â‚±17.67/hr â†’ â‚±12,900/mo

Extreme Memory (Enterprise/Heavy Analytics):
    instance_type = "db.x2g.large"    # Extreme Memory Graviton2 DB: 2 vCPUs, 32â€¯GB RAM â€” â‚±44.65/hr â†’ â‚±32,590/mo
    instance_type = "db.x2g.xlarge"   # Extreme Memory Graviton2 DB: 4 vCPUs, 64â€¯GB RAM â€” â‚±89.30/hr â†’ â‚±65,180/mo
    instance_type = "db.x2iedn.xlarge"# Extreme Memory Intel DB: 4 vCPUs, 128â€¯GB RAM â€” â‚±121.98/hr â†’ â‚±89,050/mo
*/

disk_size     = "75" # 10GB
volume_type   = "gp3"

db_name = "app_db"
db_username = "root"
db_password = "password"